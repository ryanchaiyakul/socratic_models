{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_cha(raw):\n",
    "    ret = \"@UTF8\\n@Begin\\n@Languages:\\teng\\n@Participants:\\tSPE0 GUIDE Speaker, SPE1 FOLLOWER Speaker\\n@ID:\teng|llm_debate|SPE0|||||Speaker|||\\n@ID:\teng|llm_debate|SPE1|||||Speaker|||\\n\"\n",
    "    for line in raw[3:]:\n",
    "        ret += \"*SPE{}:\\t{}.\\n\".format(\"0\" if line[0] == 'g' else '1', line[2:-4])\n",
    "    return ret + \"@End\"\n",
    "\n",
    "import pathlib\n",
    "\n",
    "folder_path = pathlib.Path('transcripts')\n",
    "output_path = pathlib.Path('2-9-2025')\n",
    "for transcript in folder_path.rglob(\"*\"):\n",
    "    with transcript.open('r') as f:\n",
    "        with output_path.joinpath('{}.cha'.format(transcript.stem)).open('w') as o:\n",
    "            o.write(map_to_cha(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_cha_file(input_file, output_file, n=1):\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        previous_speaker = None\n",
    "        previous_utterance = None\n",
    "        previous_word_count = 0\n",
    "\n",
    "        for line in infile:\n",
    "            # Check if the line is a speaker utterance\n",
    "            match = re.match(r'^\\*(\\w+):\\s*(.+)$', line)\n",
    "            if match:\n",
    "                speaker, utterance = match.groups()\n",
    "                word_count = len(utterance.split())\n",
    "\n",
    "                # Strip trailing period if it exists\n",
    "                if utterance.endswith('.'):\n",
    "                    utterance = utterance[:-1]\n",
    "\n",
    "                # Check if the current utterance should be merged with the previous one\n",
    "                if (previous_speaker == speaker and\n",
    "                    (previous_word_count <= n or word_count <= n)):\n",
    "                    # Merge with the previous utterance\n",
    "                    combined_utterance = f\"{previous_utterance}, {utterance}\"\n",
    "                    outfile.write(f'*{speaker}:\\t{combined_utterance}.\\n')  # Add period at the end\n",
    "                    previous_utterance = None  # Reset to avoid double-combining\n",
    "                else:\n",
    "                    # Write the previous utterance if it exists\n",
    "                    if previous_utterance is not None:\n",
    "                        outfile.write(f'*{previous_speaker}:\\t{previous_utterance}.\\n')\n",
    "                    # Update previous speaker, utterance, and word count\n",
    "                    previous_speaker = speaker\n",
    "                    previous_utterance = utterance\n",
    "                    previous_word_count = word_count\n",
    "            else:\n",
    "                # Write the previous utterance if it exists\n",
    "                if previous_utterance is not None:\n",
    "                    outfile.write(f'*{previous_speaker}:\\t{previous_utterance}.\\n')\n",
    "                    previous_utterance = None\n",
    "                # Write non-utterance lines directly\n",
    "                outfile.write(line)\n",
    "                previous_speaker = None\n",
    "\n",
    "        # Write the last utterance if it exists\n",
    "        if previous_utterance is not None:\n",
    "            outfile.write(f'*{previous_speaker}:\\t{previous_utterance}.\\n')\n",
    "\n",
    "import pathlib\n",
    "\n",
    "# Example usage\n",
    "folder_path = pathlib.Path('2-9-2025')\n",
    "output_path = pathlib.Path('test')\n",
    "i = 0\n",
    "for transcript in folder_path.rglob(\"*\"):\n",
    "    if i > 15:\n",
    "        break\n",
    "    process_cha_file(transcript, output_path.joinpath('{}.cha'.format(transcript.stem)), n = 10)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import socratic_model\n",
    "\n",
    "folder = 'test'\n",
    "\n",
    "analysis = socratic_model.Analysis(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e850ac2d2c4dbeb8ce7ed7c4570c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EVM:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dee36255aec44b7b2077e32afc3795e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37d79bed54b42429fafd32ac645b896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Levenshtein:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis.evm(20)\n",
    "analysis.levenshtein(20)\n",
    "analysis.workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
